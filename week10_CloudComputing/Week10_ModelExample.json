{"paragraphs":[{"text":"%spark\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.linalg.DenseVector\nimport org.apache.spark.sql.functions.udf\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.classification.MultilayerPerceptronClassifier\n\n\n\nprintln(\"Spark version: \" + sc.version);\nSystem.getProperty(\"java.version\")","user":"anonymous","dateUpdated":"2019-04-10T01:01:42+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true,"tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.SparkContext\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.feature.VectorAssembler\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.classification.LogisticRegression\nimport org.apache.spark.ml.linalg.DenseVector\nimport org.apache.spark.sql.functions.udf\nimport org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.classification.MultilayerPerceptronClassifier\nSpark version: 2.4.0\nres5: String = 1.8.0_181\n"}]},"apps":[],"jobName":"paragraph_1554595226054_1165142885","id":"20180903-230256_2046584255","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-10T01:01:42+0000","dateFinished":"2019-04-10T01:01:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:339"},{"text":"%md\n## Be mindful of editors\n##### The panel below looks like it's just output. The editor is hidden because it contains a lot of code that would otherwise make the notebook slightly hard to read. Un-hide the editor and skim the code!","user":"anonymous","dateUpdated":"2019-04-09T22:21:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Be mindful of editors</h2>\n<h5>The panel below looks like it&rsquo;s just output. The editor is hidden because it contains a lot of code that would otherwise make the notebook slightly hard to read. Un-hide the editor and skim the code!</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1554595226057_1783404885","id":"20190221-223911_2070915267","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-09T22:21:43+0000","dateFinished":"2019-04-09T22:21:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:340"},{"text":"%spark\n\n// Unpack the probability vector to a more useful form.\nval toArr: Any => Array[Double] = _.asInstanceOf[DenseVector].toArray\n\n// Generate udfs, so we can apply these to our data. \nval toArrUdf = udf(toArr)\n\n// Super ugly. The Probability array is a DenseVector, and basically none of the functions work on it. \ndef convertProbArray (raw : DataFrame) : DataFrame = {\n    // This is what wwe would like to do, but sometimes this won't work on cloud. Use hack. \n    //var expanded = raw.withColumn(\"prob_array\",toArrUdf($\"probability\"))\n    \n    // Bring probabilities locally, compute the mapping, then send back to the grid. \n    var tmp_df = sc.parallelize(raw.select(\"probability\").collect().map(r => (r(0).asInstanceOf[DenseVector].toArray))).toDF(\"prob_array\");\n    tmp_df = tmp_df.withColumn(\"rowId\", monotonically_increasing_id());\n    \n    var output = raw.withColumn(\"rowId\", monotonically_increasing_id());\n    var joined = output.join(tmp_df, output(\"rowId\") === tmp_df(\"rowId\"));\n    \n    return joined;\n};\n\n\n\ndef expandColumns (raw : DataFrame) : DataFrame = {\n    var expanded = convertProbArray(raw);\n    \n    // Now split out the probabilities.\n    expanded = expanded.withColumn(\"prob_p\", $\"prob_array\"(0)).withColumn(\"prob_c\", $\"prob_array\"(1)).withColumn(\"prob_3\", $\"prob_array\"(2));\n    \n    expanded = expanded.withColumn(\"distEntropy\", expr(\"-1.0 * ((prob_p*log(prob_p))  + (prob_c*log(prob_c)) + (prob_3*log(prob_3)))\"));\n    expanded = expanded.withColumn(\"rho\", expr(\" -1.0 * log(prob_array[next_status])\"));\n    return expanded;\n};\n\ndef filterData (raw : DataFrame) : DataFrame = {\n    var df_filtered = raw.filter($\"MTM_LTV\" > 0.0).filter($\"MTM_LTV\" < 2.0);\n    df_filtered = df_filtered.filter($\"INCENTIVE\" > -1.0).filter($\"CREDIT_SCORE\" > 0);\n    df_filtered = df_filtered.filter($\"NEXT_STATUS\" >= 0).filter($\"NEXT_STATUS\" <= 2);\n    df_filtered = df_filtered.filter($\"AGE\" >= 0).filter($\"STATUS\" === 1);\n    \n    // Go ahead and add the status columns here. \n    df_filtered = df_filtered.withColumn(\"actual_p\", expr(\" case when next_status = 0 then 1.0 else 0.0 end\"));\n    df_filtered = df_filtered.withColumn(\"actual_c\", expr(\" case when next_status = 1 then 1.0 else 0.0 end\"));\n    df_filtered = df_filtered.withColumn(\"actual_3\", expr(\" case when next_status = 2 then 1.0 else 0.0 end\"));\n    \n    return df_filtered;\n};\n\n\ndef centerColumn (exemplar : DataFrame, raw_data : DataFrame, column_name : String, column_renamed : String) : DataFrame = {\n    val target_col = exemplar(column_name);\n    val col_mean : Double = exemplar.select(avg(target_col)).collect()(0)(0).asInstanceOf[Double]\n    var col_dev : Double = exemplar.select(stddev_pop(target_col)).collect()(0)(0).asInstanceOf[Double]\n    \n    if(col_dev <= 0.0) {\n        col_dev = 1.0;\n    }\n    \n    val output_col = raw_data(column_name);\n    val output_data = raw_data.withColumn(column_renamed, (output_col - col_mean) / col_dev);\n    \n    return output_data;\n}\n\ndef assembleCenteredFeatures (exemplar : DataFrame, raw_data : DataFrame, feature_cols : Array[String]) : DataFrame = {\n    val remapped = feature_cols.map(a => a + \"_normalized\");\n    \n    var updated = raw_data;\n    \n    for(i <- 0 until feature_cols.size) {\n       updated = centerColumn(exemplar, updated, feature_cols(i), remapped(i));\n    }\n    \n    val assembler = new VectorAssembler().setInputCols(remapped).setOutputCol(\"features\");\n    updated = assembler.transform(updated);\n    \n    for(i <- 0 until feature_cols.size) {\n      updated = updated.drop(remapped(i));\n    }\n    \n    return updated;\n}\n","user":"anonymous","dateUpdated":"2019-04-10T12:45:35+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":true,"results":{},"enabled":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"distributionEntropy: (v: org.apache.spark.ml.linalg.DenseVector)Double\nklDivergence: (label: Int, v: org.apache.spark.ml.linalg.DenseVector)Double\nbool2number: (b: Boolean)Double\ntoArr: Any => Array[Double] = <function1>\ndistH: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\nrho: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function2>,DoubleType,Some(List(IntegerType, org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\nboolToNumber: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,DoubleType,Some(List(BooleanType)))\ntoArrUdf: org.apache.spark.sql.expressions.UserDefinedFunction = UserDefinedFunction(<function1>,ArrayType(DoubleType,false),None)\nexpandColumns: (raw: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\nfilterData: (raw: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\ncenterColumn: (exemplar: org.apache.spark.sql.DataFrame, raw_data: org.apache.spark.sql.DataFrame, column_name: String, column_renamed: String)org.apache.spark.sql.DataFrame\nassembleCenteredFeatures: (exemplar: org.apache.spark.sql.DataFrame, raw_data: org.apache.spark.sql.DataFrame, feature_cols: Array[String])org.apache.spark.sql.DataFrame\n"}]},"apps":[],"jobName":"paragraph_1554595226057_951938482","id":"20190221-223142_263181235","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-10T01:01:49+0000","dateFinished":"2019-04-10T01:01:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:341"},{"text":"%spark\nval df_clean1 = filterData(spark.read.parquet(\"gs://data-d5aa6d4b-e3ac-45ac-a65e-d6a2be7dbc8c-us-east1/data/spark_2001_parquet\")).limit(20 * 1000 * 1000);\n//val df_clean1 = filterData(spark.read.parquet(\"gs://data-d5aa6d4b-e3ac-45ac-a65e-d6a2be7dbc8c-us-east1/data/df_c_1\"));\nval df_clean2 = filterData(spark.read.parquet(\"gs://data-d5aa6d4b-e3ac-45ac-a65e-d6a2be7dbc8c-us-east1/data/df_c_2\"));\nval df_dirty1 = filterData(spark.read.parquet(\"gs://data-d5aa6d4b-e3ac-45ac-a65e-d6a2be7dbc8c-us-east1/data/spark_2006_parquet\")).limit(20 * 1000 * 1000);\n//val df_dirty1 = filterData(spark.read.parquet(\"gs://data-d5aa6d4b-e3ac-45ac-a65e-d6a2be7dbc8c-us-east1/data/df_d_1\"));\nval df_dirty2 = filterData(spark.read.parquet(\"gs://data-d5aa6d4b-e3ac-45ac-a65e-d6a2be7dbc8c-us-east1/data/df_d_2\"));\n\ndf_clean1.registerTempTable(\"df_clean1\")\ndf_clean2.registerTempTable(\"df_clean2\")\ndf_dirty1.registerTempTable(\"df_dirty1\")\ndf_dirty2.registerTempTable(\"df_dirty2\")","user":"anonymous","dateUpdated":"2019-04-10T12:45:51+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true,"tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"org.apache.spark.SparkException: Job 1888 cancelled part of cancelled job group zeppelin-2E8G4KADV-20180903-230321_676902992\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1888)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1823)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:906)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:906)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:906)\n  at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:906)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2078)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2058)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2047)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n  at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat$.mergeSchemasInParallel(ParquetFileFormat.scala:633)\n  at org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.inferSchema(ParquetFileFormat.scala:241)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:180)\n  at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$6.apply(DataSource.scala:180)\n  at scala.Option.orElse(Option.scala:289)\n  at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:179)\n  at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:373)\n  at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:643)\n  at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:627)\n  ... 52 elided\n"}]},"apps":[],"jobName":"paragraph_1554595226058_-2080762465","id":"20180903-230321_676902992","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-10T01:01:57+0000","dateFinished":"2019-04-10T01:02:08+0000","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:342"},{"text":"%sql \n\nSELECT * \nFROM df_clean1\nLIMIT 10\n","user":"anonymous","dateUpdated":"2019-04-09T19:39:20+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"ID":"string","SEQUENCE_NUMBER":"string","SOURCE":"string","AGE":"string","CREDIT_SCORE":"string","STATUS":"string","NEXT_STATUS":"string","FIRSTTIME_BUYER":"string","TERM":"string","MI_PERCENT":"string","UNIT_COUNT":"string","OCCUPANCY_STATUS":"string","ORIG_CLTV":"string","ORIG_DTI":"string","ORIG_UPB":"string","ORIG_LTV":"string","ORIG_INTRATE":"string","CHANNEL":"string","PRODUCT_TYPE":"string","PROPERTY_STATE":"string","PROPERTY_TYPE":"string","PREPAYMENT_PENALTY":"string","LOAN_PURPOSE":"string","UPB":"string","MTM_LTV":"string","INCENTIVE":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true,"tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.spark2CreateContext(BaseSparkScalaInterpreter.scala:189)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.createSparkContext(BaseSparkScalaInterpreter.scala:124)\norg.apache.zeppelin.spark.SparkScala211Interpreter.open(SparkScala211Interpreter.scala:89)\norg.apache.zeppelin.spark.NewSparkInterpreter.open(NewSparkInterpreter.java:102)\norg.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:62)\norg.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)\norg.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:617)\norg.apache.zeppelin.scheduler.Job.run(Job.java:188)\norg.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\njava.util.concurrent.FutureTask.run(FutureTask.java:266)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.spark2CreateContext(BaseSparkScalaInterpreter.scala:189)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.createSparkContext(BaseSparkScalaInterpreter.scala:124)\norg.apache.zeppelin.spark.SparkScala211Interpreter.open(SparkScala211Interpreter.scala:89)\norg.apache.zeppelin.spark.NewSparkInterpreter.open(NewSparkInterpreter.java:102)\norg.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:62)\norg.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)\norg.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:617)\norg.apache.zeppelin.scheduler.Job.run(Job.java:188)\norg.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\njava.util.concurrent.FutureTask.run(FutureTask.java:266)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1486)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.buildReaderWithPartitionValues(ParquetFileFormat.scala:328)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:312)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:310)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDDs(DataSourceScanExec.scala:330)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:247)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:339)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3384)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2759)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.zeppelin.spark.SparkZeppelinContext.showData(SparkZeppelinContext.java:108)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:135)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:103)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:633)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1554595226058_49968100","id":"20190221-223414_502076469","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-09T18:07:01+0000","dateFinished":"2019-04-09T18:07:01+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:343"},{"text":"%sql \nselect age, count(1) AS value\nfrom df_clean1\ngroup by age\norder by age","user":"anonymous","dateUpdated":"2019-04-09T19:39:20+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"age":"string","value":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"age","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"value","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true,"tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.spark2CreateContext(BaseSparkScalaInterpreter.scala:189)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.createSparkContext(BaseSparkScalaInterpreter.scala:124)\norg.apache.zeppelin.spark.SparkScala211Interpreter.open(SparkScala211Interpreter.scala:89)\norg.apache.zeppelin.spark.NewSparkInterpreter.open(NewSparkInterpreter.java:102)\norg.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:62)\norg.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)\norg.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:617)\norg.apache.zeppelin.scheduler.Job.run(Job.java:188)\norg.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\njava.util.concurrent.FutureTask.run(FutureTask.java:266)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:498)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.spark2CreateContext(BaseSparkScalaInterpreter.scala:189)\norg.apache.zeppelin.spark.BaseSparkScalaInterpreter.createSparkContext(BaseSparkScalaInterpreter.scala:124)\norg.apache.zeppelin.spark.SparkScala211Interpreter.open(SparkScala211Interpreter.scala:89)\norg.apache.zeppelin.spark.NewSparkInterpreter.open(NewSparkInterpreter.java:102)\norg.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:62)\norg.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)\norg.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:617)\norg.apache.zeppelin.scheduler.Job.run(Job.java:188)\norg.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\njava.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\njava.util.concurrent.FutureTask.run(FutureTask.java:266)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\njava.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:100)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1486)\n\tat org.apache.spark.sql.execution.datasources.parquet.ParquetFileFormat.buildReaderWithPartitionValues(ParquetFileFormat.scala:328)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:312)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:310)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDDs(DataSourceScanExec.scala:330)\n\tat org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:92)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)\n\tat org.apache.spark.sql.execution.aggregate.HashAggregateExec.inputRDDs(HashAggregateExec.scala:151)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3384)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2545)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2759)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.zeppelin.spark.SparkZeppelinContext.showData(SparkZeppelinContext.java:108)\n\tat org.apache.zeppelin.spark.SparkSqlInterpreter.interpret(SparkSqlInterpreter.java:135)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.interpret(LazyOpenInterpreter.java:103)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:633)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"}]},"apps":[],"jobName":"paragraph_1554595226058_-526315312","id":"20180903-230408_574703797","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-09T18:00:46+0000","dateFinished":"2019-04-09T18:00:46+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:344"},{"text":"%sql \nselect age, count(1) AS value\nfrom df_dirty1 \ngroup by age\norder by age","user":"anonymous","dateUpdated":"2019-04-10T12:45:11+0000","config":{"tableHide":false,"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"age":"string","value":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"age","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"value","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"age\tvalue\n0\t1151047\n1\t1170730\n2\t1179432\n3\t1178987\n4\t1173835\n5\t1166329\n6\t1159614\n7\t1152833\n8\t1148235\n9\t1144504\n10\t1138217\n11\t1129564\n12\t1121337\n13\t1109292\n14\t1097234\n15\t1084888\n16\t1072218\n17\t1058916\n18\t1045380\n19\t1031495\n20\t1018967\n21\t1006780\n22\t994744\n23\t982289\n24\t969246\n25\t955064\n26\t939844\n27\t923185\n28\t904246\n29\t883994\n30\t863551\n31\t842437\n32\t820523\n33\t798502\n34\t776454\n35\t754449\n36\t734093\n37\t715848\n38\t698871\n39\t683899\n40\t669878\n41\t656518\n42\t643549\n43\t630935\n44\t618232\n45\t605131\n46\t592441\n47\t580016\n48\t567941\n49\t556557\n50\t545253\n51\t534462\n52\t523789\n53\t512972\n54\t502427\n55\t492065\n56\t482683\n57\t473739\n58\t464823\n59\t456465\n60\t448307\n61\t440470\n62\t431969\n63\t423262\n64\t414187\n65\t404892\n66\t395429\n67\t385866\n68\t375697\n69\t365705\n70\t355415\n71\t345367\n72\t334596\n73\t324344\n74\t314173\n75\t304425\n76\t295427\n77\t286103\n78\t277295\n79\t268806\n80\t260928\n81\t253350\n82\t245937\n83\t239123\n84\t232580\n85\t226882\n86\t221717\n87\t217007\n88\t212680\n89\t208940\n90\t205276\n91\t201711\n92\t198634\n93\t195656\n94\t192640\n95\t189946\n96\t186955\n97\t184021\n98\t181448\n99\t178896\n100\t176149\n101\t173642\n102\t170952\n103\t168331\n104\t165944\n105\t163750\n106\t161305\n107\t159025\n108\t156411\n109\t154330\n110\t152237\n111\t150044\n112\t147927\n113\t145859\n114\t143869\n115\t141856\n116\t139743\n117\t137607\n118\t135253\n119\t132889\n120\t130944\n121\t128930\n122\t127112\n123\t125216\n124\t123341\n125\t121445\n126\t119328\n127\t107321\n128\t96422\n129\t84670\n130\t75234\n131\t66044\n132\t57666\n133\t48527\n134\t39178\n135\t29547\n136\t18621\n137\t8775\n138\t150\n"}]},"apps":[],"jobName":"paragraph_1554595226058_253423009","id":"20190221-223005_866054232","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-09T15:57:08+0000","dateFinished":"2019-04-09T15:57:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:345"},{"text":"%md\n## Assemble the Feature Vector\n##### Select the features you plan to use below!\n\n##### You may find it slightly surprising how fast the assembler works. It is adding a column to 8 million line items in a second or two, how do you think that's accomplished? Why does it not take more time than it does? Perhaps all is not quite as it appears here. \n","user":"anonymous","dateUpdated":"2019-04-09T19:39:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554595226059_-887815562","id":"20190221-224242_2075960118","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-09T04:26:21+0000","dateFinished":"2019-04-09T04:26:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:346"},{"text":"%spark\n\n\nvar feature_cols = Array(\"AGE\", \"MTM_LTV\", \"INCENTIVE\", \"CREDIT_SCORE\");\n\nvar exemplar = df_clean1.limit(100*1000);\n\n// This is pretty expensive. \nvar dfa_clean1 = assembleCenteredFeatures(exemplar, df_clean1, feature_cols);\nval dfa_clean2 = assembleCenteredFeatures(exemplar, df_clean2, feature_cols);\nval dfa_dirty1 = assembleCenteredFeatures(exemplar, df_dirty1, feature_cols);\nval dfa_dirty2 = assembleCenteredFeatures(exemplar, df_dirty2, feature_cols);\n\n// N.B: This is a vacuous set of regressors. It's (effectively) just an intercept, so a LR on this will just assign each transition its average value for every loan. You should be able to do better than this on almost any metric, and shouldn't be doing worse. \nvar vacuous = assembleCenteredFeatures(exemplar, df_clean1,  Array(\"STATUS\"));\n\n// Sample the fitting set. \nval sample_size = 100 * 1000.0;\nval sample_frac = sample_size / dfa_clean1.count();\nval fitting_set = dfa_clean1.sample(false,sample_frac,seed=832338);\n\ndfa_clean1.registerTempTable(\"dfa_clean1\");","user":"anonymous","dateUpdated":"2019-04-09T19:39:22+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true,"tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"feature_cols: Array[String] = Array(AGE, MTM_LTV, INCENTIVE, CREDIT_SCORE)\nexemplar: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [ID: bigint, SEQUENCE_NUMBER: string ... 24 more fields]\ndfa_clean1: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 25 more fields]\ndfa_clean2: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 25 more fields]\ndfa_dirty1: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 25 more fields]\ndfa_dirty2: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 25 more fields]\nvacuous: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 25 more fields]\nsample_size: Double = 100000.0\nsample_frac: Double = 0.001740527760738978\nfitting_set: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [ID: bigint, SEQUENCE_NUMBER: string ... 25 more fields]\nwarning: there was one deprecation warning; re-run with -deprecation for details\n"}]},"apps":[],"jobName":"paragraph_1554595226059_557892414","id":"20180903-230431_1794196576","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-09T15:03:34+0000","dateFinished":"2019-04-09T15:08:08+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:347"},{"text":"%md\n## Which stages are slow? \n##### Again below, it doesn't really matter how many data sets we apply a model to, that doesn't appear to require any time. Only the model fitting takes time, split these into different panels and you'll see. Guesses as to why? \n\n","user":"anonymous","dateUpdated":"2019-04-09T19:39:25+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554595226059_-1430808715","id":"20190221-224657_480095749","dateCreated":"2019-04-07T00:00:26+0000","dateStarted":"2019-04-09T04:27:30+0000","dateFinished":"2019-04-09T04:27:30+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:348"},{"text":"%sql \n\nSELECT * \nFROM dfa_clean1\nLIMIT 10","user":"anonymous","dateUpdated":"2019-04-09T19:39:25+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"ID":"string","SEQUENCE_NUMBER":"string","SOURCE":"string","AGE":"string","CREDIT_SCORE":"string","STATUS":"string","NEXT_STATUS":"string","FIRSTTIME_BUYER":"string","TERM":"string","MI_PERCENT":"string","UNIT_COUNT":"string","OCCUPANCY_STATUS":"string","ORIG_CLTV":"string","ORIG_DTI":"string","ORIG_UPB":"string","ORIG_LTV":"string","ORIG_INTRATE":"string","CHANNEL":"string","PRODUCT_TYPE":"string","PROPERTY_STATE":"string","PROPERTY_TYPE":"string","PREPAYMENT_PENALTY":"string","LOAN_PURPOSE":"string","UPB":"string","MTM_LTV":"string","INCENTIVE":"string","features":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"ID\tSEQUENCE_NUMBER\tSOURCE\tAGE\tCREDIT_SCORE\tSTATUS\tNEXT_STATUS\tFIRSTTIME_BUYER\tTERM\tMI_PERCENT\tUNIT_COUNT\tOCCUPANCY_STATUS\tORIG_CLTV\tORIG_DTI\tORIG_UPB\tORIG_LTV\tORIG_INTRATE\tCHANNEL\tPRODUCT_TYPE\tPROPERTY_STATE\tPROPERTY_TYPE\tPREPAYMENT_PENALTY\tLOAN_PURPOSE\tUPB\tMTM_LTV\tINCENTIVE\tfeatures\n3416473272786044798\tF101Q2448135\t1\t5\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t149000.0\t0.7189551839338335\t0.0014255767599254954\t[-0.6092944041398524,0.5852653873927663,-0.5463390971408755,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t6\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t149080.53\t0.711108744905593\t0.0017176807478240935\t[-0.5845051370537002,0.538299218707293,-0.5027844460160781,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t7\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t148946.21\t0.7031176566152202\t0.001975522203020247\t[-0.559715869967548,0.4904672277524974,-0.4643385668366502,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t8\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t148811.13\t0.6944380389277142\t0.0022635146881346893\t[-0.5349266028813957,0.4385139293237917,-0.421396968175295,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t9\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t148675.29\t0.6854181631130037\t0.002541598770750955\t[-0.5101373357952435,0.38452395915885396,-0.37993277835425304,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t10\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t148538.69\t0.6762372478548555\t0.002819223712213978\t[-0.4853480687090912,0.32957006056239546,-0.33853704953879477,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t11\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t148401.32\t0.66744577760044\t0.0030811191803735982\t[-0.460558801622939,0.2769472499503328,-0.29948669001129136,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t12\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t148263.18\t0.6603971028692811\t0.0033427201942033413\t[-0.43576953453678674,0.2347562324402058,-0.260480235586564,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t13\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t148124.26\t0.6534188588224856\t0.0035950896490165862\t[-0.4109802674506345,0.19298678953105886,-0.2228502681286669,-0.27729416507690946]\n3416473272786044798\tF101Q2448135\t1\t14\t673\t1\t1\tfalse\t360\t0.0\t1\t0\t0.75\t0.3\t150000.0\t0.75\t0.0675\t3\t0\tCA\t3\tfalse\t2\t147984.56\t0.6467124009755442\t0.0038311575622037436\t[-0.38619100036448223,0.15284416822376026,-0.18765096915779872,-0.27729416507690946]\n"}]},"apps":[],"jobName":"paragraph_1554596102474_-1810992957","id":"20190407-001502_984367033","dateCreated":"2019-04-07T00:15:02+0000","dateStarted":"2019-04-09T15:08:15+0000","dateFinished":"2019-04-09T15:08:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:349"},{"text":"%spark\n\nvar start = 0L;\nvar end = 0L;\n\n// Vacuous LR Model. \nval lr = new LogisticRegression().setMaxIter(100).setLabelCol(\"NEXT_STATUS\").setFeaturesCol(\"features\");\n\nstart = System.currentTimeMillis();\nval vacuousModel = lr.fit(vacuous);\nend = System.currentTimeMillis();\nprintln(\"Vacuous Logistic Regression Fitting time (ms): \" + (end - start));\n\nvar vacuous_pred = expandColumns(vacuousModel.transform(vacuous)); // This is just a comparison to benchmark against.","user":"anonymous","dateUpdated":"2019-04-09T19:39:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"start: Long = 0\nend: Long = 0\nlr: org.apache.spark.ml.classification.LogisticRegression = logreg_aa619af1d417\nstart: Long = 1554822505287\nvacuousModel: org.apache.spark.ml.classification.LogisticRegressionModel = LogisticRegressionModel: uid = logreg_aa619af1d417, numClasses = 3, numFeatures = 1\nend: Long = 1554822734965\nVacuous Logistic Regression Fitting time (ms): 229678\nvacuous_pred: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554783683541_1293166843","id":"20190409-042123_1515242688","dateCreated":"2019-04-09T04:21:23+0000","dateStarted":"2019-04-09T15:08:24+0000","dateFinished":"2019-04-09T15:12:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:350"},{"text":"%spark\n\n// Random Forest Model. \nval rf = new RandomForestClassifier().setLabelCol(\"NEXT_STATUS\").setFeaturesCol(\"features\").setNumTrees(12).setMaxDepth(10)\nstart = System.currentTimeMillis();\nval model = rf.fit(fitting_set);\nend = System.currentTimeMillis();\nprintln(\"Random Forest Fitting time (ms): \" + (end - start));\n\nvar rf_pred = expandColumns(model.transform(dfa_clean1)); // This contains the fitting sample, but also lots of other data.\nvar rf_pred2 = expandColumns(model.transform(dfa_clean2));\nvar rf_pred_dirty = expandColumns(model.transform(dfa_dirty1));\nvar rf_pred2_dirty = expandColumns(model.transform(dfa_dirty2));","user":"anonymous","dateUpdated":"2019-04-09T19:39:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"rf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_1355c0dc8fe6\nstart: Long = 1554823393892\nmodel: org.apache.spark.ml.classification.RandomForestClassificationModel = RandomForestClassificationModel (uid=rfc_1355c0dc8fe6) with 12 trees\nend: Long = 1554823509623\nRandom Forest Fitting time (ms): 115731\nrf_pred: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\nrf_pred2: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\nrf_pred_dirty: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\nrf_pred2_dirty: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554783704405_498078977","id":"20190409-042144_1275096384","dateCreated":"2019-04-09T04:21:44+0000","dateStarted":"2019-04-09T15:23:13+0000","dateFinished":"2019-04-09T15:25:10+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:351"},{"text":"%spark\n// Logistic Regression Model. \nval lr = new LogisticRegression().setMaxIter(100).setRegParam(0.001).setElasticNetParam(0.001).setLabelCol(\"NEXT_STATUS\").setFeaturesCol(\"features\");\n\nstart = System.currentTimeMillis();\nval lrModel = lr.fit(fitting_set);\nend = System.currentTimeMillis();\nprintln(\"Logistic Regression Fitting time (ms): \" + (end - start));\n\nvar lr_pred = expandColumns(lrModel.transform(dfa_clean1)); // This contains the fitting sample, but also lots of other data.\nvar lr_pred2 = expandColumns(lrModel.transform(dfa_clean2));\nvar lr_pred_dirty = expandColumns(lrModel.transform(dfa_dirty1));\nvar lr_pred2_dirty = expandColumns(lrModel.transform(dfa_dirty2));","user":"anonymous","dateUpdated":"2019-04-09T19:39:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"lr: org.apache.spark.ml.classification.LogisticRegression = logreg_1bd26362a80a\nstart: Long = 1554824752211\nlrModel: org.apache.spark.ml.classification.LogisticRegressionModel = LogisticRegressionModel: uid = logreg_1bd26362a80a, numClasses = 3, numFeatures = 4\nend: Long = 1554824817017\nLogistic Regression Fitting time (ms): 64806\nlr_pred: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\nlr_pred2: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\nlr_pred_dirty: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\nlr_pred2_dirty: org.apache.spark.sql.DataFrame = [ID: bigint, SEQUENCE_NUMBER: string ... 37 more fields]\n"}]},"apps":[],"jobName":"paragraph_1554783723905_-1287737431","id":"20190409-042203_150055429","dateCreated":"2019-04-09T04:22:03+0000","dateStarted":"2019-04-09T15:45:51+0000","dateFinished":"2019-04-09T15:46:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:352"},{"text":"%spark\n\n// Now we add the MLP model. \nval status_count = 3;\nval layers = Array[Int](feature_cols.size, 4, status_count)\nval mlp_fitter = new MultilayerPerceptronClassifier().setLabelCol(\"NEXT_STATUS\").setLayers(layers).setSeed(1234L).setMaxIter(1000).setSolver(\"l-bfgs\");\n//val mlp_fitter = new MultilayerPerceptronClassifier().setLabelCol(\"NEXT_STATUS\").setLayers(layers).setSeed(1234L).setMaxIter(1000).setSolver(\"gd\");\n\nstart = System.currentTimeMillis();\nval mlpModel = mlp_fitter.fit(fitting_set);\nend = System.currentTimeMillis();\nprintln(\"Perceptron Fitting time (ms)[\" + fitting_set.count() + \"]: \" + (end - start));\n\nvar mlp_pred = expandColumns(mlpModel.transform(dfa_clean1)); // This contains the fitting sample, but also lots of other data.\nvar mlp_pred2 = expandColumns(mlpModel.transform(dfa_clean2));\nvar mlp_pred_dirty = expandColumns(mlpModel.transform(dfa_dirty1));\nvar mlp_pred2_dirty = expandColumns(mlpModel.transform(dfa_dirty2));\n","user":"anonymous","dateUpdated":"2019-04-09T19:39:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554595318940_630012539","id":"20190407-000158_930599382","dateCreated":"2019-04-07T00:01:58+0000","dateStarted":"2019-04-09T04:30:18+0000","dateFinished":"2019-04-09T04:32:19+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:353"},{"text":"%spark\n\n// Register the tables. \nvacuous_pred.registerTempTable(\"vacuous_pred\");\nrf_pred.registerTempTable(\"rf_pred\");\nlr_pred.registerTempTable(\"lr_pred\");\nmlp_pred.registerTempTable(\"mlp_pred\");\nrf_pred2.registerTempTable(\"rf_pred2\");\nlr_pred2.registerTempTable(\"lr_pred2\");\nmlp_pred2.registerTempTable(\"mlp_pred2\");\n\n// The new dirty data tables. \nlr_pred_dirty.registerTempTable(\"lr_pred_dirty\");\nlr_pred2_dirty.registerTempTable(\"lr_pred2_dirty\");\nrf_pred_dirty.registerTempTable(\"rf_pred_dirty\");\nrf_pred2_dirty.registerTempTable(\"rf_pred2_dirty\");\nmlp_pred_dirty.registerTempTable(\"mlp_pred_dirty\");\nmlp_pred2_dirty.registerTempTable(\"mlp_pred2_dirty\");","user":"anonymous","dateUpdated":"2019-04-09T19:39:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554783737709_1745963728","id":"20190409-042217_792788204","dateCreated":"2019-04-09T04:22:17+0000","dateStarted":"2019-04-09T04:35:59+0000","dateFinished":"2019-04-09T04:36:01+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:354"},{"text":"%md\n## First, what sort of performance are we getting overall\n\n##### The first one is just a benchmark, see if you can beat that model","user":"anonymous","dateUpdated":"2019-04-09T19:39:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>First, what sort of performance are we getting overall</h2>\n<h5>The first one is just a benchmark, see if you can beat that model</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1554652541369_-1839789736","id":"20190407-155541_67789668","dateCreated":"2019-04-07T15:55:41+0000","dateStarted":"2019-04-09T19:25:45+0000","dateFinished":"2019-04-09T19:25:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:355"},{"text":"%sql\nSELECT * \nFROM (select \"vacuous_pred\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from vacuous_pred ) \nUNION ALL\n(select \"rf_pred\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from rf_pred ) \nUNION ALL\n(select \"lr_pred\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from lr_pred ) \nUNION ALL\n(select \"mlp_pred\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from mlp_pred ) \nUNION ALL\n(select \"rf_pred2\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from rf_pred2 ) \nUNION ALL\n(select \"lr_pred2\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from lr_pred2 ) \nUNION ALL\n(select \"mlp_pred2\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from mlp_pred2 ) \nUNION ALL\n(select \"rf_pred_dirty\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from rf_pred_dirty ) \nUNION ALL\n(select \"lr_pred_dirty\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from lr_pred_dirty ) \nUNION ALL\n(select \"mlp_pred_dirty\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from mlp_pred_dirty ) \nUNION ALL\n(select \"rf_pred2_dirty\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from rf_pred2_dirty ) \nUNION ALL\n(select \"lr_pred2_dirty\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from lr_pred2_dirty ) \nUNION ALL\n(select \"mlp_pred2_dirty\" AS label, avg(distEntropy), avg(rho), avg(prob_p), avg(actual_p), avg(prob_c), avg(actual_c), avg(prob_3), avg(actual_3) from mlp_pred2_dirty ) ","user":"anonymous","dateUpdated":"2019-04-09T19:45:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"label":"string","avg(distEntropy)":"string","avg(rho)":"string","avg(prob_p)":"string","avg(actual_p)":"string","avg(prob_c)":"string","avg(actual_c)":"string","avg(prob_3)":"string","avg(actual_3)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652462439_-507717482","id":"20190407-155422_842763145","dateCreated":"2019-04-07T15:54:22+0000","dateStarted":"2019-04-09T19:25:49+0000","dateFinished":"2019-04-09T19:25:51+0000","status":"ERROR","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:356"},{"text":"%md\n## Now examine the bad loans. \n\n##### The first one is just a benchmark, see if you can beat that model\n","user":"anonymous","dateUpdated":"2019-04-09T19:39:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652357348_-786544389","id":"20190407-155237_1478467837","dateCreated":"2019-04-07T15:52:37+0000","dateStarted":"2019-04-09T04:39:46+0000","dateFinished":"2019-04-09T04:39:46+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:357"},{"text":"%sql\n\nSELECT *\nFROM vacuous_pred \nLIMIT 10\n","user":"anonymous","dateUpdated":"2019-04-09T19:39:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"ID":"string","SEQUENCE_NUMBER":"string","SOURCE":"string","AGE":"string","CREDIT_SCORE":"string","STATUS":"string","NEXT_STATUS":"string","FIRSTTIME_BUYER":"string","TERM":"string","MI_PERCENT":"string","UNIT_COUNT":"string","OCCUPANCY_STATUS":"string","ORIG_CLTV":"string","ORIG_DTI":"string","ORIG_UPB":"string","ORIG_LTV":"string","ORIG_INTRATE":"string","CHANNEL":"string","PRODUCT_TYPE":"string","PROPERTY_STATE":"string","PROPERTY_TYPE":"string","PREPAYMENT_PENALTY":"string","LOAN_PURPOSE":"string","UPB":"string","MTM_LTV":"string","INCENTIVE":"string","features":"string","rawPrediction":"string","probability":"string","prediction":"string","prob_array":"string","prob_p":"string","prob_c":"string","prob_3":"string","actual_p":"string","actual_c":"string","actual_3":"string","distEntropy":"string","rho":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554656512094_467953324","id":"20190407-170152_1365326216","dateCreated":"2019-04-07T17:01:52+0000","dateStarted":"2019-04-09T04:39:49+0000","dateFinished":"2019-04-09T04:39:52+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:358"},{"text":"%sql\nselect rho, sum(rho), count(*) AS count\nfrom vacuous_pred\nGROUP BY rho","user":"anonymous","dateUpdated":"2019-04-09T19:39:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"rho":"string","sum(rho)":"string","count":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[],"groups":[],"values":[]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554597898181_-1914842369","id":"20190407-004458_27544964","dateCreated":"2019-04-07T00:44:58+0000","dateStarted":"2019-04-09T04:41:05+0000","dateFinished":"2019-04-09T04:41:11+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:359"},{"text":"%md\n## Now the real models.\n\n##### Can you make a model here that beats the benchmark? How much penalty in terms of total rho do you pay for it? ","user":"anonymous","dateUpdated":"2019-04-09T19:39:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652408062_2072501639","id":"20190407-155328_1340465911","dateCreated":"2019-04-07T15:53:28+0000","dateStarted":"2019-04-07T16:29:33+0000","dateFinished":"2019-04-07T16:29:33+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:360"},{"text":"%sql\nselect round(rho, 0), sum(rho)\nfrom rf_pred\nWHERE rho > 4.0\nGROUP BY round(rho, 0)\nORDER BY round(rho, 0)","user":"anonymous","dateUpdated":"2019-04-09T19:39:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"round(rho, 0)":"string","sum(rho)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"round(rho, 0)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"sum(rho)","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554651493528_405259646","id":"20190407-153813_1266660548","dateCreated":"2019-04-07T15:38:13+0000","dateStarted":"2019-04-09T04:42:11+0000","dateFinished":"2019-04-09T04:42:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:361"},{"text":"%sql\nselect round(rho, 0), sum(rho)\nfrom lr_pred\nWHERE rho > 5.0\nGROUP BY round(rho, 0)\nORDER BY round(rho, 0)","user":"anonymous","dateUpdated":"2019-04-09T19:39:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"round(rho, 0)":"string","sum(rho)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"round(rho, 0)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"sum(rho)","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652612194_988159629","id":"20190407-155652_1461354010","dateCreated":"2019-04-07T15:56:52+0000","dateStarted":"2019-04-07T16:49:43+0000","dateFinished":"2019-04-07T16:50:51+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:362"},{"text":"%sql\nselect round(rho, 0), sum(rho)\nfrom mlp_pred\nWHERE rho > 5.0\nGROUP BY round(rho, 0)\nORDER BY round(rho, 0)","user":"anonymous","dateUpdated":"2019-04-09T19:39:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"round(rho, 0)":"string","sum(rho)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"round(rho, 0)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"sum(rho)","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652610038_1371736920","id":"20190407-155650_189812898","dateCreated":"2019-04-07T15:56:50+0000","dateStarted":"2019-04-07T16:50:22+0000","dateFinished":"2019-04-07T16:51:19+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:363"},{"text":"%sql\nselect round(rho, 0), sum(rho)\nfrom rf_pred_dirty\nWHERE rho > 5.0\nGROUP BY round(rho, 0)\nORDER BY round(rho, 0)","user":"anonymous","dateUpdated":"2019-04-09T19:39:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"round(rho, 0)":"string","sum(rho)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"round(rho, 0)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"sum(rho)","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652638594_1033032983","id":"20190407-155718_1943987305","dateCreated":"2019-04-07T15:57:18+0000","dateStarted":"2019-04-07T16:50:52+0000","dateFinished":"2019-04-07T16:53:12+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:364"},{"text":"%sql\nselect round(rho, 0), sum(rho)\nfrom lr_pred_dirty\nWHERE rho > 5.0\nGROUP BY round(rho, 0)\nORDER BY round(rho, 0)","user":"anonymous","dateUpdated":"2019-04-09T19:39:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"round(rho, 0)":"string","sum(rho)":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"round(rho, 0)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"sum(rho)","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652653622_683363153","id":"20190407-155733_1536222168","dateCreated":"2019-04-07T15:57:33+0000","dateStarted":"2019-04-07T16:51:20+0000","dateFinished":"2019-04-07T16:54:15+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:365"},{"text":"%sql\nselect round(rho, 0), sum(rho), count(*) AS count\nfrom mlp_pred_dirty\nWHERE rho > 5.0\nGROUP BY round(rho, 0)\nORDER BY round(rho, 0)","user":"anonymous","dateUpdated":"2019-04-09T19:39:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"round(rho, 0)":"string","sum(rho)":"string","count":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"round(rho, 0)","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"sum(rho)","index":1,"aggr":"sum"}]},"helium":{}}},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554652664816_-1910929540","id":"20190407-155744_2132741784","dateCreated":"2019-04-07T15:57:44+0000","dateStarted":"2019-04-09T04:43:13+0000","dateFinished":"2019-04-09T04:43:23+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:366"},{"text":"%sql\n","user":"anonymous","dateUpdated":"2019-04-09T19:39:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","tableHide":false,"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1554654625078_-454613278","id":"20190407-163025_1064376683","dateCreated":"2019-04-07T16:30:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:367"}],"name":"Week10/ModelExample","id":"2E8G4KADV","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{},"checkpoint":{"message":"Fixed functions."}}